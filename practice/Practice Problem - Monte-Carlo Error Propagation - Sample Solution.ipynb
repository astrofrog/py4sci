{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Practice Problem - Monte-Carlo Error Propagation - Sample Solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start off by defining the values and uncertainties, along with some constants:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Defined constant(s)\n",
      "G = 6.67384e-11  # SI units\n",
      "\n",
      "# Define values to sample from\n",
      "mean_m_1 = 40.e4\n",
      "sigma_m_1 = 0.05e4\n",
      "mean_m_2 = 30.e4\n",
      "sigma_m_2 = 0.1e4\n",
      "mean_r = 3.2\n",
      "sigma_r = 0.01"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now compute the mean and uncertainty in the force using standard error propagation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute mean and error of force\n",
      "mean_f = G * mean_m_1 * mean_m_2 / mean_r ** 2\n",
      "sigma_f = mean_f * np.sqrt((sigma_m_1 / mean_m_2) ** 2\n",
      "                           + (sigma_m_2 / mean_m_2) ** 2\n",
      "                           + 4. * (sigma_r / mean_r) ** 2)\n",
      "print(mean_f, sigma_f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also compute this using Monte-Carlo error propagation. We sample ``N`` initial values that are drawn from the initial distributions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 1000000\n",
      "m_1 = np.random.normal(mean_m_1, sigma_m_1, N)\n",
      "m_2 = np.random.normal(mean_m_2, sigma_m_2, N)\n",
      "r = np.random.normal(mean_r, sigma_r, N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and for each sample, we can compute the final value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = G * m_1 * m_2 / r ** 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can print for these the mean and standard deviation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.mean(F), np.std(F))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "which is similar to the values found above, but in fact we have the full distribution of values, which we can plot a histogram for, along with a curve showing the Gaussian function for the result found from standard error propagation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define range of output values for plotting\n",
      "xmin = 0.75\n",
      "xmax = 0.82\n",
      "\n",
      "# Define Gaussian function\n",
      "\n",
      "def gaussian(x, mu, sigma):\n",
      "    norm = 1. / (sigma * np.sqrt(2. * np.pi))\n",
      "    return norm * np.exp(-(x - mu) ** 2. / (2. * sigma ** 2))\n",
      "\n",
      "x = np.linspace(xmin, xmax, 1000)\n",
      "y = gaussian(x, mean_f, sigma_f)\n",
      "\n",
      "plt.hist(F, bins=50, range=[xmin, xmax], normed=True)\n",
      "plt.plot(x, y, color='red', lw=3)\n",
      "plt.xlabel(\"Force (N)\")\n",
      "plt.ylabel(\"Relative Probability\")\n",
      "plt.xlim(xmin, xmax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The two agree very nicely. Now let's repeat this, but with larger initial errors:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The distribution of the sampled values agrees well with that found from standard error propagation. We can now repeat the experiment with larger uncertainties:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define values to sample from\n",
      "mean_m_1 = 40.e4\n",
      "sigma_m_1 = 2.e4\n",
      "mean_m_2 = 30.e4\n",
      "sigma_m_2 = 10.e4\n",
      "mean_r = 3.2\n",
      "sigma_r = 1.0\n",
      "\n",
      "# Define range of output values for plotting\n",
      "xmin = -1.\n",
      "xmax = 5.\n",
      "\n",
      "# Define number of samples\n",
      "N = 1000000\n",
      "\n",
      "## STANDARD ERROR PROPAGATION\n",
      "\n",
      "# Compute mean and error of force\n",
      "mean_f = G * mean_m_1 * mean_m_2 / mean_r ** 2\n",
      "sigma_f = mean_f * np.sqrt((sigma_m_1 / mean_m_2) ** 2\n",
      "                           + (sigma_m_2 / mean_m_2) ** 2\n",
      "                           + 4. * (sigma_r / mean_r) ** 2)\n",
      "\n",
      "# Define Gaussian function\n",
      "x = np.linspace(xmin, xmax, 1000)\n",
      "y = gaussian(x, mean_f, sigma_f)\n",
      "\n",
      "## MONTE-CARLO ERROR PROPAGATION\n",
      "\n",
      "# Sample from initial values\n",
      "m_1 = np.random.normal(mean_m_1, sigma_m_1, N)\n",
      "m_2 = np.random.normal(mean_m_2, sigma_m_2, N)\n",
      "r = np.random.normal(mean_r, sigma_r, N)\n",
      "\n",
      "# Compute final values\n",
      "F = G * m_1 * m_2 / r ** 2\n",
      "\n",
      "## PLOTTING\n",
      "\n",
      "plt.hist(F, bins=50, range=[xmin, xmax], normed=True)\n",
      "plt.plot(x, y, color='red', lw=3)\n",
      "plt.xlabel(\"Force (N)\")\n",
      "plt.ylabel(\"Relative Probability\")\n",
      "plt.xlim(xmin, xmax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The distribution of sampled points is now significantly non-Gaussian, which is normal because the uncertainties are large, and standard error propagation only works for small errors. The conclusion is that Monte-Carlo propagation is easier to code (because one doesn't need to remember all the propagation equations) and is also more correct because it can take into account non-Gaussian distributions (of input or output)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}